{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412964caef6097d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Shifting the image by a margin of pixels\n",
    "import skimage.transform as trans\n",
    "from scipy import signal\n",
    "from PIL import Image\n",
    "from scipy import stats as stat\n",
    "from itertools import product\n",
    "\n",
    "# Image Analysis\n",
    "import numpy as np\n",
    "from scipy.fft import fft, ifft\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from tifffile import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io, exposure, data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import stats as st\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from numpy import diff\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage.filters import unsharp_mask\n",
    "# from wand.image import Image as ImageWand\n",
    "from numpy.polynomial import polynomial as P\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38422e99844ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def save_video(filename, frames):\n",
    "    # frames_rgb: (N, H, W, 3) uint8 in RGB\n",
    "    h, w = frames.shape[1], frames.shape[2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(filename, fourcc, 15.0, (w, h), isColor=True)\n",
    "\n",
    "    for fr in frames:\n",
    "        fr_bgr = cv2.cvtColor(fr, cv2.COLOR_GRAY2BGR)\n",
    "        out.write(fr_bgr)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Saved {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560911a-3f9b-497b-bf1c-0a9a491b902c",
   "metadata": {},
   "source": [
    "# Registration 1 - Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d891940-a4a5-4e5c-8b92-31918e227f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, prange\n",
    "import numpy as np\n",
    "\n",
    "# # Dirty Implementation of Shifting Images\n",
    "# def ShiftedImage_2D(Image, XShift, YShift):\n",
    "#     # Quick guard\n",
    "#     if (XShift == 0 and YShift == 0):\n",
    "#         return Image;\n",
    "\n",
    "#     M = np.float32([\n",
    "#     [1, 0, XShift],\n",
    "#     [0, 1, YShift]\n",
    "#     ]);\n",
    "\n",
    "#     shifted = cv2.warpAffine(Image, M, (Image.shape[1], Image.shape[0]));\n",
    "#     shifted_image = shifted\n",
    "\n",
    "#     # Shift Down\n",
    "#     if (YShift > 0):\n",
    "#         shifted_image = shifted_image[YShift:];\n",
    "#         shifted_image = np.pad(shifted_image, ((YShift, 0), (0, 0)), 'edge'); # Pad Up\n",
    "\n",
    "#     # Shift Up\n",
    "#     if (YShift < 0):\n",
    "#         shifted_image = shifted_image[:shifted.shape[0] - abs(YShift)];\n",
    "#         shifted_image = np.pad(shifted_image, ((0, abs(YShift)), (0, 0)), 'edge'); # Pad Down\n",
    "\n",
    "#     # Shift Left\n",
    "#     if (XShift > 0):\n",
    "#         shifted_image = np.delete(shifted_image, slice(0, XShift), 1);\n",
    "#         shifted_image = np.pad(shifted_image, ((0, 0), (XShift, 0)), 'edge'); # Pad Left\n",
    "\n",
    "#     if (XShift < 0):\n",
    "#         shifted_image = np.delete(shifted_image, slice(shifted.shape[1] - abs(XShift), shifted.shape[1]), 1);\n",
    "#         shifted_image = np.pad(shifted_image, ((0, 0), (0, abs(XShift))), 'edge'); # Pad Right\n",
    "\n",
    "#     return shifted_image\n",
    "\n",
    "from numba import jit, prange\n",
    "import numpy as np\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def ShiftedImage_2D_numba(Image, XShift, YShift):\n",
    "    \"\"\"Ultra-fast numba-compiled version.\"\"\"\n",
    "    if XShift == 0 and YShift == 0:\n",
    "        return Image.copy()\n",
    "\n",
    "    h, w = Image.shape[:2]\n",
    "    \n",
    "    if Image.ndim == 3:\n",
    "        result = np.zeros((h, w, Image.shape[2]), dtype=Image.dtype)\n",
    "        channels = Image.shape[2]\n",
    "    else:\n",
    "        result = np.zeros((h, w), dtype=Image.dtype)\n",
    "        channels = 1\n",
    "\n",
    "    # Parallel pixel-wise shifting with bounds checking\n",
    "    for i in prange(h):\n",
    "        for j in prange(w):\n",
    "            src_i = i - YShift\n",
    "            src_j = j - XShift\n",
    "            \n",
    "            if 0 <= src_i < h and 0 <= src_j < w:\n",
    "                if Image.ndim == 3:\n",
    "                    for c in range(channels):\n",
    "                        result[i, j, c] = Image[src_i, src_j, c]\n",
    "                else:\n",
    "                    result[i, j] = Image[src_i, src_j]\n",
    "            else:\n",
    "                # Edge padding: find nearest valid pixel\n",
    "                nearest_i = max(0, min(h - 1, src_i))\n",
    "                nearest_j = max(0, min(w - 1, src_j))\n",
    "                \n",
    "                if Image.ndim == 3:\n",
    "                    for c in range(channels):\n",
    "                        result[i, j, c] = Image[nearest_i, nearest_j, c]\n",
    "                else:\n",
    "                    result[i, j] = Image[nearest_i, nearest_j]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# sum of absolute differences (SAD) metric alignment\n",
    "# Optimized version\n",
    "@jit(nopython=True, parallel=True)\n",
    "def SAD(a, b):\n",
    "    # Vectorized SAD; extremely fast\n",
    "    flat_a = a.ravel()\n",
    "    flat_b = b.ravel()\n",
    "    total = 0.0\n",
    "    for i in prange(len(flat_a)):\n",
    "        total += abs(float(flat_a[i]) - float(flat_b[i]))\n",
    "    return total / len(flat_a)\n",
    "\n",
    "# We use a Tree Search Algorithm to find possible alignment\n",
    "# Let Image_1 be the orginal\n",
    "# Let Image_2 be the aligned\n",
    "# Displacement object is our nodes, [x,y]\n",
    "# Assumption, there is always a better alignment up, down, left, and right if its not the same image\n",
    "def alignment_MAE(Image_1, Image_2, depth_cap):\n",
    "    iterative_cap = 0;\n",
    "    Best_SAD = SAD(Image_1, Image_2);\n",
    "    Best_Displacement = [0,0];\n",
    "    q = [];\n",
    "    visited_states = [[0,0]];  # Add (0,0) displacement\n",
    "    q.append(Best_Displacement); # Append (0,0) displacement\n",
    "\n",
    "    while (iterative_cap != depth_cap and q):\n",
    "        curr_state = q.pop(0);\n",
    "        x = curr_state[0];\n",
    "        y = curr_state[1];\n",
    "\n",
    "        iterative_cap += 1;\n",
    "\n",
    "        movement_arr = [\n",
    "            [x, y - 1], # Up\n",
    "            [x, y + 1], # Down\n",
    "            [x + 1, y], # Left\n",
    "            [x - 1, y], # Right\n",
    "            [x - 1, y - 1], # Diagonal\n",
    "            [x + 1, y + 1], # Diagonal\n",
    "            [x + 1, y - 1], # Diagonal\n",
    "            [x - 1, y + 1], # Diagonal\n",
    "        ]\n",
    "\n",
    "        for move in movement_arr:\n",
    "            if (move not in visited_states):\n",
    "                visited_states.append(move); # Marked as Visited\n",
    "\n",
    "                # Perform shift and calculate\n",
    "                new_image = ShiftedImage_2D_numba(Image_2, move[0], move[1]);\n",
    "                cand_SAD = SAD(Image_1, new_image);\n",
    "\n",
    "                if (cand_SAD < Best_SAD):\n",
    "                    Best_SAD = cand_SAD;\n",
    "                    Best_Displacement = move;\n",
    "\n",
    "                    q.append(move);\n",
    "\n",
    "                # This means we cannot find a better move.\n",
    "    return Best_Displacement, Best_SAD\n",
    "\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "# This was a good fix for edge detection\n",
    "@jit(nopython=True, parallel=True)\n",
    "def compute_row_means_2d(img):\n",
    "    \"\"\"Custom row mean computation for 2D arrays.\"\"\"\n",
    "    rows, cols = img.shape\n",
    "    row_means = np.empty(rows, dtype=np.float64)\n",
    "    for i in prange(rows):\n",
    "        total = 0.0\n",
    "        for j in range(cols):\n",
    "            total += float(img[i, j])\n",
    "        row_means[i] = total / cols\n",
    "    return row_means\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def compute_row_means_3d(img):\n",
    "    \"\"\"Custom row mean computation for 3D arrays.\"\"\"\n",
    "    rows, cols, channels = img.shape\n",
    "    row_means = np.empty(rows, dtype=np.float64)\n",
    "    for i in prange(rows):\n",
    "        total = 0.0\n",
    "        for j in range(cols):\n",
    "            for k in range(channels):\n",
    "                total += float(img[i, j, k])\n",
    "        row_means[i] = total / (cols * channels)\n",
    "    return row_means\n",
    "\n",
    "@jit(nopython=True)\n",
    "def edge_detection_numba_fixed(img):\n",
    "    \"\"\"\n",
    "    Numba-compatible vertical edge detection function.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image (2D or 3D numpy array)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (top_edge_row, bottom_edge_row)\n",
    "    \"\"\"\n",
    "    # Compute row-wise brightness averages\n",
    "    if img.ndim == 3:\n",
    "        row_brightness = compute_row_means_3d(img)\n",
    "    else:\n",
    "        row_brightness = compute_row_means_2d(img)\n",
    "    \n",
    "    # Calculate gradient manually\n",
    "    gradient = np.empty(len(row_brightness) - 1, dtype=np.float64)\n",
    "    for i in range(len(gradient)):\n",
    "        gradient[i] = row_brightness[i + 1] - row_brightness[i]\n",
    "    \n",
    "    # Suppress extreme values near edges\n",
    "    height = img.shape[0]\n",
    "    for i in range(len(gradient)):\n",
    "        if (i <= 100 or i >= height - 100) and abs(gradient[i]) >= 150:\n",
    "            gradient[i] = 0.0\n",
    "    \n",
    "    # Find top edge (maximum gradient in upper half)\n",
    "    half_height = height // 2\n",
    "    max_val = -np.inf\n",
    "    top_edge = 0\n",
    "    \n",
    "    for i in range(min(half_height, len(gradient))):\n",
    "        if gradient[i] > max_val:\n",
    "            max_val = gradient[i]\n",
    "            top_edge = i\n",
    "    \n",
    "    # Find bottom edge (minimum gradient in lower half)\n",
    "    min_val = np.inf\n",
    "    bottom_edge = half_height\n",
    "    \n",
    "    for i in range(half_height, len(gradient)):\n",
    "        if gradient[i] < min_val:\n",
    "            min_val = gradient[i]\n",
    "            bottom_edge = i\n",
    "    \n",
    "    return top_edge, bottom_edge\n",
    "\n",
    "# # @jit(nopython=True, parallel=True)\n",
    "# def edge_detection_optimized(img):\n",
    "#     \"\"\"\n",
    "#     Ultra-fast vertical edge detection using brightness gradient analysis.\n",
    "    \n",
    "#     Returns:\n",
    "#         tuple: (top_edge_row, bottom_edge_row) positions\n",
    "#     \"\"\"\n",
    "#     # Vectorized row-wise brightness computation\n",
    "#     if img.ndim == 3:\n",
    "#         row_brightness = np.mean(np.mean(img, axis=2), axis=1)\n",
    "#     else:\n",
    "#         row_brightness = np.mean(img, axis=1)\n",
    "    \n",
    "#     # Calculate first derivative efficiently\n",
    "#     gradient = np.diff(row_brightness)\n",
    "    \n",
    "#     # Vectorized noise suppression for edge regions\n",
    "#     height = img.shape[0]\n",
    "#     edge_mask = (np.arange(len(gradient)) <= 100) | (np.arange(len(gradient)) >= height - 100)\n",
    "#     extreme_mask = (np.abs(gradient) >= 150)\n",
    "#     gradient[edge_mask & extreme_mask] = 0\n",
    "    \n",
    "#     # Find valid extrema with spatial constraints\n",
    "#     half_height = height // 2\n",
    "    \n",
    "#     # Top edge: strongest positive gradient in upper half\n",
    "#     upper_region = gradient[:half_height]\n",
    "#     if len(upper_region) > 0 and np.max(upper_region) > 0:\n",
    "#         top_edge = np.argmax(upper_region)\n",
    "#     else:\n",
    "#         top_edge = 0\n",
    "    \n",
    "#     # Bottom edge: strongest negative gradient in lower half  \n",
    "#     lower_region = gradient[half_height:]\n",
    "#     if len(lower_region) > 0 and np.min(lower_region) < 0:\n",
    "#         bottom_edge = half_height + np.argmin(lower_region)\n",
    "#     else:\n",
    "#         bottom_edge = height - 1\n",
    "        \n",
    "#     return top_edge, bottom_edge\n",
    "\n",
    "def remove_stage_jitter_MAE_opt(img_array, iteration_depth : int = 1000, m = False, verbose : bool = False, mcm : bool = False):\n",
    "    # Add Scores path just for curiosity\n",
    "    scores = []\n",
    "    X_shifts = []\n",
    "    Y_shifts = []\n",
    "    shifted_images = []\n",
    "\n",
    "    if img_array.ndim != 3:\n",
    "        print(\"Give a series of grayscale images. Shape: {}\".format(img_array.shape))\n",
    "\n",
    "    base = exposure.rescale_intensity(img_array[0])\n",
    "\n",
    "    base_top, base_bottom = edge_detection_numba_fixed(base)\n",
    "\n",
    "    # TODO: verify\n",
    "    if base.ndim == 3:\n",
    "        base = base[:, :, 0] # Reduce to the 2D\n",
    "\n",
    "    iteration = 0 # TODO: implement in more pythonic way\n",
    "\n",
    "    for _frame in tqdm(img_array[1:]):\n",
    "        iteration += 1\n",
    "\n",
    "        template_image = exposure.rescale_intensity(_frame) # Get rid of low exposure\n",
    "\n",
    "        template_top, template_bottom = edge_detection_numba_fixed(template_image)\n",
    "\n",
    "        if template_image.ndim == 3:\n",
    "            template_image = template_image[:, :, 0] # Reduce to the 2D\n",
    "\n",
    "        displacement, score = alignment_MAE(base, template_image, iteration_depth)\n",
    "        scores.append(score)\n",
    "        # print(\"SCORE:\", score)\n",
    "\n",
    "        if mcm:\n",
    "            displacement[0] = 0\n",
    "\n",
    "        X_shifts.append(displacement[0])\n",
    "        Y_shifts.append(int(np.mean([(base_top - template_top), (base_bottom -  template_bottom)])))\n",
    "        shifted_image = ShiftedImage_2D_numba(template_image, displacement[0], int(np.mean([(base_top - template_top), (base_bottom -  template_bottom)]))) # X,Y\n",
    "        shifted_images.append(shifted_image)\n",
    "\n",
    "        # For my purposes\n",
    "        # background = Image.fromarray(base)\n",
    "        # overlay = Image.fromarray(shifted_image)\n",
    "        #\n",
    "        # new_img = Image.blend(background, overlay, 0.5)\n",
    "\n",
    "        # print(\"Overlay for image to compare against jitter (PHC)\", iteration, \":\", filename)\n",
    "        # plt.imshow(new_img)\n",
    "        # plt.show()\n",
    "        #\n",
    "        # # Write the new image in target folder\n",
    "        # cv2.imwrite(os.path.join(output_path, filename), shifted_image);\n",
    "\n",
    "    # print (\"Scores:\", scores)\n",
    "    # print(\"The X_Shifts:\", X_shifts)\n",
    "    # print(\"The Y_Shifts:\", Y_shifts)\n",
    "\n",
    "    return shifted_images, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1092a-c0ad-4fbf-b5ae-932e4ef8f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test registration 1 optimized\n",
    "import nd2\n",
    "import time\n",
    "\n",
    "test_dataset = nd2.imread('/Volumes/Server_Data/1-HHLN/22.20 Lauren Data/1_10_lauren_replicate_1/3-SR_1_10_6hPre-C_Plain_M9_TS_MC2.nd2', dask=True)\n",
    "# test_dataset = nd2.imread(\n",
    "#    '/Users/hiram/Documents/EVERYTHING/20-29 Research/22 OliveiraLab/22.12 ND2 analyzer/nd2-analyzer/SR_1_5_2h_Pre-C_3h_IPTG_After10h_05_MC.nd2',\n",
    "#    dask=True)\n",
    "test_pos_over_time = test_dataset[:, 0, 0].compute()\n",
    "\n",
    "# Normalization\n",
    "plt.imshow(exposure.rescale_intensity(test_pos_over_time[0]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "frames = ((test_pos_over_time / 65535) * 255).astype(np.uint8)\n",
    "\n",
    "begin = time.time()\n",
    "aligned, scores = remove_stage_jitter_MAE_opt(frames)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Total time {end - begin}')\n",
    "\n",
    "# Save both timelapses and evaluate\n",
    "save_video(\"original_1_opt.mp4\", frames)\n",
    "save_video(\"registered_1_opt.mp4\", np.array(aligned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2523997d8ea07b",
   "metadata": {},
   "source": [
    "# Registration 1 - Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169b80090529741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirty Implementation of Shifting Images\n",
    "def ShiftedImage_2D(Image, XShift, YShift):\n",
    "    # Quick guard\n",
    "    if (XShift == 0 and YShift == 0):\n",
    "        return Image;\n",
    "\n",
    "    M = np.float32([\n",
    "    [1, 0, XShift],\n",
    "    [0, 1, YShift]\n",
    "    ]);\n",
    "\n",
    "    shifted = cv2.warpAffine(Image, M, (Image.shape[1], Image.shape[0]));\n",
    "    shifted_image = shifted\n",
    "\n",
    "    # Shift Down\n",
    "    if (YShift > 0):\n",
    "        shifted_image = shifted_image[YShift:];\n",
    "        shifted_image = np.pad(shifted_image, ((YShift, 0), (0, 0)), 'edge'); # Pad Up\n",
    "\n",
    "    # Shift Up\n",
    "    if (YShift < 0):\n",
    "        shifted_image = shifted_image[:shifted.shape[0] - abs(YShift)];\n",
    "        shifted_image = np.pad(shifted_image, ((0, abs(YShift)), (0, 0)), 'edge'); # Pad Down\n",
    "\n",
    "    # Shift Left\n",
    "    if (XShift > 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(0, XShift), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (XShift, 0)), 'edge'); # Pad Left\n",
    "\n",
    "    if (XShift < 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(shifted.shape[1] - abs(XShift), shifted.shape[1]), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (0, abs(XShift))), 'edge'); # Pad Right\n",
    "\n",
    "    return shifted_image\n",
    "\n",
    "def ShiftedImage_3D(Image, XShift, YShift):\n",
    "    # Quick guard\n",
    "    if (XShift == 0 and YShift == 0):\n",
    "        return Image;\n",
    "\n",
    "    M = np.float32([\n",
    "    [1, 0, XShift],\n",
    "    [0, 1, YShift]\n",
    "    ]);\n",
    "\n",
    "    shifted = cv2.warpAffine(Image, M, (Image.shape[1], Image.shape[0]));\n",
    "    shifted_image = shifted\n",
    "\n",
    "    # Shift Down\n",
    "    if (YShift > 0):\n",
    "        shifted_image = shifted_image[YShift:];\n",
    "        shifted_image = np.pad(shifted_image, ((YShift, 0), (0, 0), (0, 0)), 'constant', constant_values=(0,)); # Pad Up\n",
    "\n",
    "    # Shift Up\n",
    "    if (YShift < 0):\n",
    "        shifted_image = shifted_image[:shifted.shape[0] - abs(YShift)];\n",
    "        shifted_image = np.pad(shifted_image, ((0, abs(YShift)), (0, 0), (0, 0)), 'constant', constant_values=(0,)); # Pad Down\n",
    "\n",
    "    # Shift Left\n",
    "    if (XShift > 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(0, XShift), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (XShift, 0), (0, 0)), 'constant', constant_values=(0,)); # Pad Left\n",
    "\n",
    "    # Shift Up\n",
    "    if (XShift < 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(shifted.shape[1] - abs(XShift), shifted.shape[1]), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (0, abs(XShift)), (0, 0)), 'constant', constant_values=(0,)); # Pad Right\n",
    "\n",
    "    plt.imshow(shifted_image)\n",
    "    plt.show()\n",
    "\n",
    "    return shifted_image\n",
    "\n",
    "def SAD(A,B):\n",
    "    cutA = A.ravel();\n",
    "    cutB = B.ravel();\n",
    "    MAE = np.sum(np.abs(np.subtract(cutA,cutB,dtype=np.float64))) / cutA.shape[0]\n",
    "    return MAE\n",
    "\n",
    "# sum of absolute differences (SAD) metric alignment, quick n dirty\n",
    "# We use a Tree Search Algorithm to find possible alignment\n",
    "# Let Image_1 be the orginal\n",
    "# Let Image_2 be the aligned\n",
    "# Displacement object is our nodes, [x,y]\n",
    "# Assumption, there is always a better alignment up, down, left, and right if its not the same image\n",
    "def alignment_MAE(Image_1, Image_2, depth_cap):\n",
    "    iterative_cap = 0;\n",
    "    Best_SAD = SAD(Image_1, Image_2);\n",
    "    Best_Displacement = [0,0];\n",
    "    q = [];\n",
    "    visited_states = [[0,0]];  # Add (0,0) displacement\n",
    "    q.append(Best_Displacement); # Append (0,0) displacement\n",
    "\n",
    "    while (iterative_cap != depth_cap and q):\n",
    "        curr_state = q.pop(0);\n",
    "        x = curr_state[0];\n",
    "        y = curr_state[1];\n",
    "\n",
    "        iterative_cap += 1;\n",
    "\n",
    "        movement_arr = [\n",
    "            [x, y - 1], # Up\n",
    "            [x, y + 1], # Down\n",
    "            [x + 1, y], # Left\n",
    "            [x - 1, y], # Right\n",
    "            [x - 1, y - 1], # Diagonal\n",
    "            [x + 1, y + 1], # Diagonal\n",
    "            [x + 1, y - 1], # Diagonal\n",
    "            [x - 1, y + 1], # Diagonal\n",
    "        ]\n",
    "\n",
    "        for move in movement_arr:\n",
    "            if (move not in visited_states):\n",
    "                visited_states.append(move); # Marked as Visited\n",
    "\n",
    "                # Perform shift and calculate\n",
    "                new_image = ShiftedImage_2D(Image_2, move[0], move[1]);\n",
    "                cand_SAD = SAD(Image_1, new_image);\n",
    "\n",
    "                if (cand_SAD < Best_SAD):\n",
    "                    Best_SAD = cand_SAD;\n",
    "                    Best_Displacement = move;\n",
    "\n",
    "                    q.append(move);\n",
    "\n",
    "                # This means we cannot find a better move.\n",
    "\n",
    "\n",
    "    return Best_Displacement, Best_SAD\n",
    "\n",
    "# Vec4f is (x1, y1, x2, y2)\n",
    "def y_shift_emphasis(image, block_threshold, MAE_shift):\n",
    "    output_img = image;\n",
    "\n",
    "    # Need to turn into uint8 for Straight Line Detection\n",
    "    img = np.uint8(image);\n",
    "    lsd = cv2.createLineSegmentDetector(0);\n",
    "    lines_contour = lsd.detect(img)[0];\n",
    "\n",
    "    drawn_img = lsd.drawSegments(img,lines_contour);\n",
    "#     plt.imshow(drawn_img)\n",
    "#     plt.show()\n",
    "\n",
    "    horizontal_lines = {};\n",
    "    for x in lines_contour:\n",
    "        for y in x:\n",
    "            cand_gradient = abs(y[1] - y[3]);\n",
    "            if (cand_gradient < 10):\n",
    "                horizontal_lines[cand_gradient] = y;\n",
    "\n",
    "    horz = list(horizontal_lines.values())\n",
    "\n",
    "    top_y = np.min(horz);\n",
    "    bottom_y = np.max(horz);\n",
    "\n",
    "    return top_y, bottom_y\n",
    "\n",
    "# Takes in image and returns the edges for top and bottom parametrically, (x,y)\n",
    "# Takes in RGB image\n",
    "def edge_cropping_estimation_vertical(img, m):\n",
    "    main_bright = img;\n",
    "\n",
    "    local_vertical = [];\n",
    "\n",
    "    # Vertical Cutting\n",
    "    for row in range(0, main_bright.shape[0]):\n",
    "        temp_arr = [];\n",
    "        for col in range(0, main_bright.shape[1]):\n",
    "            temp_arr.append(np.mean(main_bright[row][col]));\n",
    "        local_vertical.append(np.mean(temp_arr));\n",
    "\n",
    "    # ================ Vertical axis squish ================\n",
    "    x_vertical = list(range(1, main_bright.shape[0] + 1 ));\n",
    "    y_vertical = local_vertical;\n",
    "\n",
    "    dydx_vertical = diff(y_vertical)/diff(x_vertical);\n",
    "    y_verticle_dydx = list(range(1, main_bright.shape[0]));\n",
    "\n",
    "    for i in range(0, len(dydx_vertical)):\n",
    "        # Below Crazy 150 values\n",
    "        if ((dydx_vertical[i] >= 150 and i <= 100) or (dydx_vertical[i] <= -150 and i <= 100)):\n",
    "            dydx_vertical[i] = 0;\n",
    "\n",
    "        # Above Crazy 150 values\n",
    "        if ((dydx_vertical[i] >= 150 and i >= (main_bright.shape[0] - 100)) or (dydx_vertical[i] <= -150 and (main_bright.shape[0] - 100))):\n",
    "            dydx_vertical[i] = 0;\n",
    "\n",
    "    top_m_derivatives_ind = np.argpartition(dydx_vertical, m)[m:];\n",
    "    sorted_ind_m = sorted(top_m_derivatives_ind);\n",
    "    clustered_sorted_ind_m = [];\n",
    "\n",
    "    cluster_iter_m = 0;\n",
    "    prev_m = sorted_ind_m[0];\n",
    "    cluster_sum_m = 0;\n",
    "\n",
    "    for i in range(0, len(sorted_ind_m)):\n",
    "        if (i == len(sorted_ind_m) - 1):\n",
    "            clustered_sorted_ind_m.append(int(cluster_sum_m / cluster_iter_m));\n",
    "        # If the previous value is outside the range of the current value, i\n",
    "        elif (prev_m >= (sorted_ind_m[i] + 100) or prev_m <= (sorted_ind_m[i] - 100)):\n",
    "            clustered_sorted_ind_m.append(int(cluster_sum_m / cluster_iter_m));\n",
    "            cluster_sum_m = sorted_ind_m[i];\n",
    "            cluster_iter_m = 1;\n",
    "            prev_m = sorted_ind_m[i];\n",
    "        else:\n",
    "            cluster_sum_m += sorted_ind_m[i];\n",
    "            cluster_iter_m += 1;\n",
    "            prev_m = sorted_ind_m[i];\n",
    "\n",
    "\n",
    "    print(\"The VERTICAL DERIVATIVE:\")\n",
    "    plt.plot(y_verticle_dydx, dydx_vertical);\n",
    "    for i in clustered_sorted_ind_m:\n",
    "        plt.axvline(x = i, color = 'r');\n",
    "    plt.show();\n",
    "\n",
    "    top = clustered_sorted_ind_m[0];\n",
    "    bottom = clustered_sorted_ind_m[len(clustered_sorted_ind_m) - 1];\n",
    "\n",
    "    return top, bottom;\n",
    "\n",
    "# Takes in image and returns the edges for top and bottom parametrically, (x,y)\n",
    "# Assumes Bottom is always min and top is always max\n",
    "def edge_cropping_estimation_vertical_high_low_distr(img):\n",
    "    main_bright = img;\n",
    "\n",
    "    local_vertical = [];\n",
    "\n",
    "    # Vertical Cutting\n",
    "    for row in range(0, main_bright.shape[0]):\n",
    "        temp_arr = [];\n",
    "        for col in range(0, main_bright.shape[1]):\n",
    "            temp_arr.append(np.mean(main_bright[row][col]));\n",
    "        local_vertical.append(np.mean(temp_arr));\n",
    "\n",
    "    # ================ Vertical axis squish ================\n",
    "    x_vertical = list(range(1, main_bright.shape[0] + 1 ));\n",
    "    y_vertical = local_vertical;\n",
    "\n",
    "    dydx_vertical = diff(y_vertical)/diff(x_vertical);\n",
    "    y_verticle_dydx = list(range(1, main_bright.shape[0]));\n",
    "\n",
    "    for i in range(0, len(dydx_vertical)):\n",
    "        # Below Crazy 150 values\n",
    "        if ((dydx_vertical[i] >= 150 and i <= 100) or (dydx_vertical[i] <= -150 and i <= 100)):\n",
    "            dydx_vertical[i] = 0;\n",
    "\n",
    "        # Above Crazy 150 values\n",
    "        if ((dydx_vertical[i] >= 150 and i >= (main_bright.shape[0] - 100)) or (dydx_vertical[i] <= -150 and (main_bright.shape[0] - 100))):\n",
    "            dydx_vertical[i] = 0;\n",
    "\n",
    "    max_val = np.max(dydx_vertical)\n",
    "    max_index = np.where(dydx_vertical == max_val)[0][0];\n",
    "    while(max_index > (img.shape[1]/2)):\n",
    "        print(\"Cycling max_index:\", max_index)\n",
    "        dydx_vertical[max_index] = 0; # Reset the value as it is not needed anymore\n",
    "        max_val = np.max(dydx_vertical)\n",
    "        max_index = np.where(dydx_vertical == max_val)[0][0];\n",
    "\n",
    "    min_val = np.min(dydx_vertical)\n",
    "    min_index = np.where(dydx_vertical == min_val)[0][0];\n",
    "    while(min_index < (img.shape[1]/2)):\n",
    "        print(\"Cycling min_index:\", min_index)\n",
    "        dydx_vertical[min_index] = 0; # Reset the value as it is not needed anymore\n",
    "        min_val = np.min(dydx_vertical)\n",
    "        min_index = np.where(dydx_vertical == min_val)[0][0];\n",
    "\n",
    "    print(\"The VERTICAL DERIVATIVE (Pattern Distribution):\")\n",
    "    plt.plot(y_verticle_dydx, dydx_vertical);\n",
    "    plt.axvline(x = max_index, color = 'r');\n",
    "    plt.axvline(x = min_index, color = 'r');\n",
    "    plt.show();\n",
    "\n",
    "    top = max_index\n",
    "    bottom = min_index\n",
    "\n",
    "    return top, bottom;\n",
    "\n",
    "def remove_stage_jitter_MAE(img_array, iteration_depth : int = 1000, m = False, verbose : bool = False, mcm : bool = False):\n",
    "    # Add Scores path just for curiosity\n",
    "    scores = []\n",
    "    X_shifts = []\n",
    "    Y_shifts = []\n",
    "    shifted_images = []\n",
    "\n",
    "    if img_array.ndim != 3:\n",
    "        print(\"Give a series of grayscale images. Shape: {}\".format(img_array.shape))\n",
    "\n",
    "    base = exposure.rescale_intensity(img_array[0])\n",
    "\n",
    "    base_top, base_bottom = edge_cropping_estimation_vertical_high_low_distr(base)\n",
    "    #     base_top, base_bottom = edge_cropping_estimation_vertical(base, m);\n",
    "\n",
    "    # TODO: verify\n",
    "    if base.ndim == 3:\n",
    "        base = base[:, :, 0] # Reduce to the 2D\n",
    "\n",
    "    iteration = 0 # TODO: implement in more pythonic way\n",
    "\n",
    "    for _frame in img_array[1:]:\n",
    "        iteration += 1\n",
    "\n",
    "        template_image = exposure.rescale_intensity(_frame) # Get rid of low exposure\n",
    "\n",
    "        template_top, template_bottom = edge_cropping_estimation_vertical_high_low_distr(template_image)\n",
    "\n",
    "        if template_image.ndim == 3:\n",
    "            template_image = template_image[:, :, 0] # Reduce to the 2D\n",
    "\n",
    "        displacement, score = alignment_MAE(base, template_image, iteration_depth)\n",
    "        scores.append(score)\n",
    "        print(\"SCORE:\", score)\n",
    "\n",
    "        if mcm:\n",
    "            displacement[0] = 0\n",
    "\n",
    "        X_shifts.append(displacement[0])\n",
    "        Y_shifts.append(int(np.mean([(base_top - template_top), (base_bottom -  template_bottom)])))\n",
    "        shifted_image = ShiftedImage_2D(template_image, displacement[0], int(np.mean([(base_top - template_top), (base_bottom -  template_bottom)]))) # X,Y\n",
    "        shifted_images.append(shifted_image)\n",
    "\n",
    "        # For my purposes\n",
    "        # background = Image.fromarray(base)\n",
    "        # overlay = Image.fromarray(shifted_image)\n",
    "        #\n",
    "        # new_img = Image.blend(background, overlay, 0.5)\n",
    "\n",
    "        # print(\"Overlay for image to compare against jitter (PHC)\", iteration, \":\", filename)\n",
    "        # plt.imshow(new_img)\n",
    "        # plt.show()\n",
    "        #\n",
    "        # # Write the new image in target folder\n",
    "        # cv2.imwrite(os.path.join(output_path, filename), shifted_image);\n",
    "\n",
    "    print (\"Scores:\", scores)\n",
    "    print(\"The X_Shifts:\", X_shifts)\n",
    "    print(\"The Y_Shifts:\", Y_shifts)\n",
    "\n",
    "    return shifted_images, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0c69f3acdddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test registration 1\n",
    "import nd2\n",
    "\n",
    "test_dataset = nd2.imread('/Volumes/Server_Data/1-HHLN/22.20 Lauren Data/1_10_lauren_replicate_1/3-SR_1_10_6hPre-C_Plain_M9_TS_MC2.nd2', dask=True)\n",
    "# test_dataset = nd2.imread(\n",
    "#    '/Users/hiram/Documents/EVERYTHING/20-29 Research/22 OliveiraLab/22.12 ND2 analyzer/nd2-analyzer/SR_1_5_2h_Pre-C_3h_IPTG_After10h_05_MC.nd2',\n",
    "#    dask=True)\n",
    "test_pos_over_time = test_dataset[:, 0, 0].compute()\n",
    "\n",
    "# Normalization\n",
    "norm = cv2.normalize(test_pos_over_time, None, 0, 65535, cv2.NORM_MINMAX)\n",
    "plt.imshow(norm[0], cmap='gray')\n",
    "plt.show()\n",
    "# frames: (N,H,W) uint8\n",
    "frames = ((norm / 65535) * 255).astype(np.uint8)\n",
    "frames_rgb = np.stack([frames] * 3, axis=-1)  # (N,H,W,3)\n",
    "aligned, scores = remove_stage_jitter_MAE(frames)\n",
    "\n",
    "# Save both timelapses and evaluate\n",
    "save_video(\"original_1.mp4\", frames)\n",
    "save_video(\"registered_1.mp4\", np.array(aligned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6488f56fdf89eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "597a6e7ae2c7efe2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Registration 2 - Not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e08a7a694991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirty Implementation of Shifting Images\n",
    "def ShiftedImage_2D(Image, XShift, YShift):\n",
    "    # Quick guard\n",
    "    if (XShift == 0 and YShift == 0):\n",
    "        return Image\n",
    "\n",
    "    M = np.float32([\n",
    "        [1, 0, XShift],\n",
    "        [0, 1, YShift]\n",
    "    ])\n",
    "\n",
    "    shifted = cv2.warpAffine(Image, M, (Image.shape[1], Image.shape[0]))\n",
    "    shifted_image = shifted\n",
    "\n",
    "    # Shift Down\n",
    "    if (YShift > 0):\n",
    "        shifted_image = shifted_image[YShift:]\n",
    "        shifted_image = np.pad(shifted_image, ((YShift, 0), (0, 0)), 'edge')  # Pad Up\n",
    "\n",
    "    # Shift Up\n",
    "    if (YShift < 0):\n",
    "        shifted_image = shifted_image[:shifted.shape[0] - abs(YShift)]\n",
    "        shifted_image = np.pad(shifted_image, ((0, abs(YShift)), (0, 0)), 'edge')  # Pad Down\n",
    "\n",
    "    # Shift Left\n",
    "    if (XShift > 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(0, XShift), 1)\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (XShift, 0)), 'edge')  # Pad Left\n",
    "\n",
    "    if (XShift < 0):\n",
    "        shifted_image = np.delete(shifted_image, slice(shifted.shape[1] - abs(XShift), shifted.shape[1]), 1);\n",
    "        shifted_image = np.pad(shifted_image, ((0, 0), (0, abs(XShift))), 'edge');  # Pad Right\n",
    "\n",
    "    return shifted_image\n",
    "\n",
    "# sum of absolute differences (SAD) metric alignment, quick n dirty\n",
    "def SAD(A, B):\n",
    "    cutA = A.ravel();\n",
    "    cutB = B.ravel();\n",
    "    MAE = np.sum(np.abs(np.subtract(cutA, cutB, dtype=np.float64))) / cutA.shape[0]\n",
    "    return MAE\n",
    "\n",
    "# We use a Tree Search Algorithm to find possible alignment\n",
    "# Let Image_1 be the orginal\n",
    "# Let Image_2 be the aligned\n",
    "# Displacement object is our nodes, [x,y]\n",
    "# Assumption, there is always a better alignment up, down, left, and right if its not the same image\n",
    "def alignment_MAE(Image_1, Image_2, depth_cap):\n",
    "    iterative_cap = 0\n",
    "    Best_SAD = SAD(Image_1, Image_2)\n",
    "    Best_Displacement = [0, 0]\n",
    "    q = []\n",
    "    visited_states = [[0, 0]]  # Add (0,0) displacement\n",
    "    q.append(Best_Displacement)  # Append (0,0) displacement\n",
    "\n",
    "    while (iterative_cap != depth_cap and q):\n",
    "        curr_state = q.pop(0);\n",
    "        x = curr_state[0];\n",
    "        y = curr_state[1];\n",
    "\n",
    "        iterative_cap += 1;\n",
    "\n",
    "        movement_arr = [\n",
    "            [x, y - 1],  # Up\n",
    "            [x, y + 1],  # Down\n",
    "            [x + 1, y],  # Left\n",
    "            [x - 1, y],  # Right\n",
    "            [x - 1, y - 1],  # Diagonal\n",
    "            [x + 1, y + 1],  # Diagonal\n",
    "            [x + 1, y - 1],  # Diagonal\n",
    "            [x - 1, y + 1],  # Diagonal\n",
    "        ]\n",
    "\n",
    "        for move in movement_arr:\n",
    "            if (move not in visited_states):\n",
    "                visited_states.append(move)  # Marked as Visited\n",
    "\n",
    "                # Perform shift and calculate\n",
    "                new_image = ShiftedImage_2D(Image_2, move[0], move[1])\n",
    "                cand_SAD = SAD(Image_1, new_image)\n",
    "\n",
    "                if (cand_SAD < Best_SAD):\n",
    "                    Best_SAD = cand_SAD\n",
    "                    Best_Displacement = move\n",
    "\n",
    "                    q.append(move)\n",
    "\n",
    "                # This means we cannot find a better move.\n",
    "\n",
    "    return Best_Displacement, Best_SAD\n",
    "\n",
    "# Vec4f is (x1, y1, x2, y2)\n",
    "def y_shift_emphasis(image, block_threshold, MAE_shift, plot_debug=False):\n",
    "    output_img = image\n",
    "\n",
    "    # Need to turn into uint8 for Straight Line Detection\n",
    "    img = np.uint8(image)\n",
    "    lsd = cv2.createLineSegmentDetector(0)\n",
    "    lines_contour = lsd.detect(img)[0]\n",
    "\n",
    "    if plot_debug:\n",
    "        drawn_img = lsd.drawSegments(img, lines_contour);\n",
    "        plt.imshow(drawn_img, cmap='gray')\n",
    "        plt.title('Drawn Image')\n",
    "        plt.show()\n",
    "\n",
    "    horizontal_lines = {};\n",
    "    for x in lines_contour:\n",
    "        for y in x:\n",
    "            cand_gradient = abs(y[1] - y[3])\n",
    "            if (cand_gradient < 10):\n",
    "                horizontal_lines[cand_gradient] = y\n",
    "\n",
    "    horz = list(horizontal_lines.values())\n",
    "\n",
    "    top_y = np.min(horz);\n",
    "    bottom_y = np.max(horz);\n",
    "\n",
    "    return top_y, bottom_y\n",
    "\n",
    "def remove_stage_jitter_MAE(input_images, iteration_depth, plot_debug=False):\n",
    "    # Add Scores path just for curiosity\n",
    "    scores = []\n",
    "    result = []\n",
    "\n",
    "    # # Create Output folder\n",
    "    # if (not os.path.exists(output_path)):\n",
    "    #     os.makedirs(output_path);\n",
    "\n",
    "    # # Get training image files list:\n",
    "    # image_name_arr = glob.glob(os.path.join(source_path, \"*.png\")) + glob.glob(os.path.join(source_path, \"*.tif\"));\n",
    "    # image_name_arr_sorted = sorted(image_name_arr, key = lambda x:x[48:57]);\n",
    "\n",
    "    # base_image = os.path.basename(image_name_arr_sorted[0]);\n",
    "    # base = cv2.imread(os.path.join(source_path, base_image), cv2.IMREAD_ANYDEPTH)\n",
    "\n",
    "    base = input_images[0]\n",
    "\n",
    "    if base.ndim == 3:\n",
    "        base = base[:, :, 0]  # Reduce to the 2D\n",
    "\n",
    "    base_top, base_bottom = y_shift_emphasis(base, 15, 0)\n",
    "    iteration = 0\n",
    "\n",
    "    for img in input_images[1:]:\n",
    "        iteration += 1\n",
    "        template_image = img\n",
    "\n",
    "        if template_image.ndim == 3:\n",
    "            template_image = template_image[:, :, 0]  # Reduce to the 2D\n",
    "\n",
    "        template_top, template_bottom = y_shift_emphasis(template_image, 15, 0)\n",
    "\n",
    "        displacement, score = alignment_MAE(base, template_image, iteration_depth)\n",
    "        scores.append(score)\n",
    "        shifted_image = ShiftedImage_2D(template_image, displacement[0], int(np.mean(\n",
    "            [(base_top - template_top), (base_bottom - template_bottom)])))  # X,Y\n",
    "\n",
    "        # For my purposes\n",
    "        background = Image.fromarray(np.uint8(base))\n",
    "        overlay = Image.fromarray(np.uint8(shifted_image))\n",
    "        new_img = Image.blend(background, overlay, 0.5)\n",
    "\n",
    "        if plot_debug:\n",
    "            print(\"Overlay to show frame jitter\")\n",
    "            print(\"Overlay for image\", iteration)\n",
    "            plt.imshow(new_img, cmap='gray')\n",
    "            plt.title('New Image')\n",
    "            # plt.imshow(shifted_image, cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "        # Write the new image in target folder\n",
    "        shifted_image = exposure.rescale_intensity(shifted_image)  # Get rid of low exposure\n",
    "        result.append(shifted_image)\n",
    "\n",
    "    print(\"Scores:\", scores)\n",
    "\n",
    "    return result, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Load images\n",
    "import nd2\n",
    "\n",
    "test_dataset = nd2.imread(\n",
    "    '/Users/hiram/Documents/EVERYTHING/20-29 Research/22 OliveiraLab/22.12 ND2 analyzer/nd2-analyzer/SR_1_5_2h_Pre-C_3h_IPTG_After10h_05_MC.nd2',\n",
    "    dask=True)\n",
    "test_pos_over_time = test_dataset[:, 0, 0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea061ed00001f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_pos_over_time[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd48d53217bfb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "norm = cv2.normalize(test_pos_over_time, None, 0, 65535, cv2.NORM_MINMAX)\n",
    "plt.imshow(norm[0], cmap='gray')\n",
    "plt.show()\n",
    "print('putaaa')\n",
    "# frames: (N,H,W) uint8\n",
    "frames = ((norm / 65535) * 255).astype(np.uint8)\n",
    "frames_rgb = np.stack([frames] * 3, axis=-1)  # (N,H,W,3)\n",
    "aligned, scores = remove_stage_jitter_MAE(frames, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697968f7105b8512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both timelapses and evaluate\n",
    "save_video(\"original.mp4\", frames)\n",
    "save_video(\"registered.mp4\", np.array(aligned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283c8a4fb283ff6",
   "metadata": {},
   "source": [
    "## Register with skimage (not good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef32aa563a8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.registration import phase_cross_correlation\n",
    "\n",
    "\n",
    "def register_timestack(images):\n",
    "    registered = [images[0]]  # First frame as reference\n",
    "    shifts = [(0, 0)]\n",
    "\n",
    "    for i in range(1, len(images)):\n",
    "        shift, error, phase_diff = phase_cross_correlation(\n",
    "            images[0], images[i],\n",
    "            upsample_factor=100  # for sub-pixel precision\n",
    "        )\n",
    "        registered.append(np.roll(images[i], shift.astype(int), axis=(0, 1)))\n",
    "        shifts.append(shift)\n",
    "\n",
    "    return registered, shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b0baffe08d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# frames: a NumPy array of shape (N, H, W) or (N, H, W, 3)\n",
    "def show_frames_matplotlib(frames, delay=0.1):\n",
    "    plt.ion()  # interactive mode on\n",
    "    fig, ax = plt.subplots()\n",
    "    for frame in frames:\n",
    "        ax.clear()\n",
    "        if frame.ndim == 2:\n",
    "            ax.imshow(frame, cmap='gray', vmin=0, vmax=255)\n",
    "        else:\n",
    "            ax.imshow(frame)\n",
    "        ax.axis('off')\n",
    "        display(fig)\n",
    "        plt.pause(delay)\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a464d59ff5813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Normalization\n",
    "norm = cv2.normalize(test_pos_over_time.compute(), None, 0, 65535, cv2.NORM_MINMAX)\n",
    "# plt.imshow(norm[0], cmap='gray')\n",
    "# frames: (N,H,W) uint8\n",
    "frames = ((norm / 65535) * 255).astype(np.uint8)\n",
    "frames_rgb = np.stack([frames] * 3, axis=-1)  # (N,H,W,3)\n",
    "\n",
    "# frames_rgb: (N, H, W, 3) uint8 in RGB\n",
    "h, w = frames_rgb.shape[1], frames_rgb.shape[2]\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"timelapse.mp4\", fourcc, 15.0, (w, h), isColor=True)\n",
    "\n",
    "for fr in frames_rgb:\n",
    "    fr_bgr = cv2.cvtColor(fr, cv2.COLOR_RGB2BGR)\n",
    "    out.write(fr_bgr)\n",
    "\n",
    "out.release()\n",
    "print(\"Saved timelapse.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf262db1d0a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555ed0110b7d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the registration\n",
    "registered, shifts = register_timestack(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a300c0117337d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# # frames: (N,H,W) uint8\n",
    "# frames = ((test_pos_over_time / 65535) * 255).compute().astype(np.uint8)\n",
    "# frames_rgb = np.stack([frames]*3, axis=-1)  # (N,H,W,3)\n",
    "\n",
    "# frames_rgb: (N, H, W, 3) uint8 in RGB\n",
    "h, w = frames.shape[1], frames.shape[2]\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"registered.mp4\", fourcc, 15.0, (w, h), isColor=True)\n",
    "\n",
    "for fr in registered:\n",
    "    fr_bgr = cv2.cvtColor(fr, cv2.COLOR_GRAY2BGR)\n",
    "    out.write(fr_bgr)\n",
    "\n",
    "out.release()\n",
    "print(\"Saved timelapse.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee22eeaf90f8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
